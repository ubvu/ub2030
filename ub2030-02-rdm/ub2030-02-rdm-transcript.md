# Aflevering 02 -- Toekomst van Research Data Management en Research Software Management

# Introductie

*Maurice:* Welkom bij UB 2030, de podcast over de
universiteitsbibliotheek die moet innoveren vanwege de snel veranderende
technologische ontwikkelingen en de veranderingen in het landschap
binnen onderzoek en onderwijs. Ik ben Maurice Vanderfeesten.

*David:* En ik ben David Oldenhof en vandaag gaan we praten over de
toekomst van research data management en software management.

*Maurice:* Hoe ziet het ideale plaatje voor RDM en RSM eruit in 2030?
Wat zijn de factoren die verandering teweegbrengen vandaag de dag? En
wat is de erfenis uit het verleden dat verandering moeilijk maakt? En
wat is er nodig om naar die toekomst toe te komen?

*David:* Dit bespreken we met onze gasten: Tim Pinchetti, enterprise
architect bij de VU.

*Maurice:* Meron Vermaas, coördinator research software management bij
de VU.

*David:* En Marcel Ras, coördinator van het VU netwerk research data
support. Oftewel, nerds.

## Wat is Research Data Management?


*David:* Om te beginnen met Marcel, kun je in twee zinnen uitleggen wat
we eigenlijk verstaan onder RDM en RSM?

*Marcel:* Twee zinnen? Ja, dat is lastig. Maar laat ik de definitie
gebruiken die de VU zelf daarvoor hanteert, die op onze research data
support portal ook staat. Research data management is het organiseren,
documenteren, opslaan en archiveren en delen van onderzoeksdata. En
eigenlijk zou je voor RSM, research software management, hetzelfde
kunnen zeggen, maar dan data kunnen vervangen voor software.

*David:* En waarom is dat aan de VU opgezet? Van hoelang is dat een
onderwerp aan de VU? En wat was de aanleiding geweest om dit op de kaart
te zetten en op te zetten?

*Marcel:* Het is al zeker een aantal jaren onderwerp. Naarmate
onderzoeksproces digitaler wordt, werd ook onderzoeksdata management
belangrijker. We hebben in de afgelopen vier jaar een grootschalig
programma gehad, het programma Research Data Support, waarin we allerlei
infrastructuur en dienstverleningen hebben ontwikkeld ten behoeve van
onderzoekers. En waarom is het nu belangrijk? Het helpt onderzoekers bij
het maken van keuzes in hun onderzoek. Het zorgt ervoor dat zij data
veilig kunnen opslaan, delen, dat ze daarover na kunnen denken en het is
ook een belangrijke voorwaarde voor hergebruik van data en voor
transparantie van onderzoek. Door je onderzoeksdata goed te beheren,
door er goed voor te zorgen, zorg je ook voor betrouwbaarheid en zorg je
voor reproduceerbaarheid van je onderzoek en je onderzoeksdata. En dat
heeft ook wel te maken\... Het is belangrijk geworden een aantal jaren
geleden en dat heeft ook te maken gehad met een aantal fraudegevallen
die we kennen, denk ik, allemaal. De Stapel-affaire die ook echt
research data management in een stroomversnelling heeft gebracht. Het is
ook belangrijk omdat er rondom het doen van onderzoek ook een enorme
administratieve last is voor onderzoekers en hoe beter onderzoekers hun
onderzoeksdata beheren, hoe minder die administratieve druk zou kunnen
zijn. En dat betekent ook dat we onderzoekers daarbij moeten bijstaan,
dat we onderzoekers daarbij moeten helpen. En dan komt een andere, veel
gebruikte afkorting in beeld, namelijk RDS, research data support. Dat
heeft dus één op één te maken met het managen van onderzoeksdata. Dat
waren overigens geen twee zinnen, maar goed.

*Maurice:* Nee, dat geeft helemaal niet. Hebben jullie daar iets op toe
te voegen? Tim bijvoorbeeld?

*Tim:* Ja, eigenlijk wel. Ik zou in het verlengde nog wel van
integriteit, waar Marcel het over had, nog wel wat willen toevoegen.
Want je ziet sowieso dat de positie van de universiteit als de
kennishebber binnen de maatschappij, die staat ook een beetje ter
discussie soms, hè. Je merkt toch wel een bepaalde onderstroming in onze
maatschappij dat we experts zat zijn. Een deel daarvan is een stukje
wetenschapscommunicatie, boodschappen helderder naar voren brengen. Maar
een deel daarvan is ook gewoon eigenlijk die heldere verantwoording en
transparantie over wat doe je nou en waar komen de conclusies die je
trekt in een onderzoek nou weer vandaan? Dat maakt het dus ontzettend
belangrijk dat traceerbaar is van waar is een onderzoek nou op
gebaseerd? Wat is nou de data die eraan ten grondslag ligt? En is die
data gewoon goed behandeld? Dus het is niet alleen een
reproduceerbaarheidsstukje. Het is ook gewoon direct een maatschappelijk
belang, denk ik, om te kunnen laten zien in onze eigen boekhouding
gewoon zo transparant en open te zijn als we kunnen.

*Maurice:* En geldt dat ook voor software, Meron?

*Meron:* Ja, zeker. Software heeft net een andere insteek dan data. In
zoverre, niet in de idealistische zin dat het ook herproduceerbaar moet
zijn. Maar het heeft een groot verschil in dat het uitvoerbaar is en een
soort levend ding is, terwijl de data in principe, zodra gestald en
veilig behandeld, voor de toekomst bruikbaar zou moeten kunnen blijven
als dit goed gedaan is. Terwijl software een eeuwig onderhoud vraagt,
indien je het wil blijven gebruiken. Of op zijn minst een paar extra
grote stappen om te zorgen, op een platform of ergens anders, dat het
goed opgeslagen kan worden. Dat is niet zo simpel en dat is een recent
opkomende trend om hier wat meer aandacht aan te besteden.

*Maurice:* Dus software is niet alleen platte tekst, maar het is een
soort levend iets wat in een soort runtime moet kunnen toetsen of de
data, die de input is en de output is, daarin transparantie moet bieden.
Want gegeven deze input moet je altijd uitkomen op deze output. Dat doet
software.

*Meron:* Precies, zeker. Het is meer een soort proces of een
onderzoeksinstrument wat net anders behandeld moet worden. Wat daar nog
bij komt, is dat het een soort creatief proces is om het te ontwikkelen,
waardoor intellectuele eigendomsrechten ook net wat anders zijn. Dat
vraagt ook nog een extra stukje aandacht.

*Maurice:* Een beetje flauwe vraag, maar die is al een beetje
beantwoord, wat is de aanleiding geweest om dit op te zetten? Dat is
inderdaad de transparantie die je wil, veroorzaakt voor
reproduceerbaarheid maar ook voor het vertrouwen in het publieke domein,
in de wetenschap terug te brengen. Klopt dat? Heb ik dat zo een beetje
goed samengevat?

*Meron:* Ja, zeker. Het is zowel die dingen als dat het in
reproduceerbaarheid natuurlijk voor het goed van de wetenschap zelf is
als iemand verder kan bouwen. Want er wordt niet per se van een
wetenschapper gevraagd om een stukje code of software eeuwig in leven te
houden, maar zoveel mogelijk stappen te doen om het over te kunnen
dragen kan ook naar de community en dan kan het voortgezet worden en
verder gebruikt, want het is niet een one use only. Liever niet.

*Maurice:* Tim heeft nog een opmerking zo meteen en dat wil ik ook
misschien aan Tim vragen: heeft dat ook nog een economisch aspect dat
dat goed gebeurt, dat je wetenschap niet meer opnieuw hoeft te doen of
wetenschap kan versnellen of iets dergelijks? Maar misschien kan Tim
daar nog verder op inhaken.

*Tim:* Ik wilde nog op één ding, op aanleiding, even terugkomen en dat
is ook wel een stukje economisch gesprek misschien. Ook even heel
praktisch voor en onderzoeker, het wordt gewoon ook vaak geëist. Een
deel ervan is ideale vergezichten of idealisme, sorry, maar een deel was
ook gewoon van\... Een subsidieverstrekker eist sommige dingen van je,
dat je dat goed regelt en daar zit dan misschien wel een stukje
idealisme vanuit overheids- of subsidieverstrekkersperspectief in, hè.
We willen vanuit overheidsperspectief dat onderzoek wordt gedaan op een
manier die open is, dat die reproduceerbaar is en herbruikbaar is. En
dat van daaruit de subsidievoorwaarden daaraan worden aangepast. Maar
voor een onderzoeker is het ook gewoon vaak heel praktisch: ik moet dit
doen, want mijn subsidieverstrekker die eist dat. Daar moeten we, denk
ik, ook gewoon bij stilstaan. Het is niet een hobby van de meeste
onderzoekers om hun data te managen of om hun software te managen.
Sommigen wel, sommigen vinden het belangrijk, maar niet iedereen. Dat
moet je ook meenemen in hoe je het vervolgens gaat opzetten.

## Toekomst driehoek
*Maurice:* Ja, precies. Ik zie dat Meron nog iets wou toevoegen, maar we
gaan even door naar The Futures Triangle. Want we gaan de toekomst van
research data management en research software management schetsen aan de
hand van de toekomstdriehoek. De toekomstdriehoek is een eenvoudig
instrument, ontwikkeld door Sohail Inayatullah, om het verleden, heden
en toekomst in kaart te brengen en zo om de ruimte van de
waarschijnlijke toekomst te verkennen. Het basisidee is dat er drie
dimensies zijn, die het meest waarschijnlijk de toekomst vormgeven: het
gewicht van het verleden wat je mee zeult, de druk van het heden en de
aantrekkingskracht van de toekomst. De spanning en interactie tussen
deze drie krachten in die driehoek creëert de ruimte waarbinnen de meest
waarschijnlijke toekomst zich kan afspelen.

## Druk van het Heden


*Maurice:* We beginnen dan bij het heden, en daar hadden we het nu al een
beetje over, hè, over de economische factoren en ook over beleidsmatige
factoren van wie moet dat nou, dat research data management. Want het
heden bevat vaak veel factoren die drijfveren zijn voor verandering, die
je nu al kan zien aankomen. Die invloedsfactoren zijn vaak sociaal,
technologisch, economisch en politiek van aard. Eén van de bekendste
politieke veranderfactoren was bijvoorbeeld, om een beeld te vormen, het
besluit van John F. Kennedy in begin jaren \'60 om een man naar de maan
te sturen. Dat heeft een enorme ontwikkeling teweeggebracht. Dat was een
politiek besluit en dat duwt een bepaalde kant uit, de ontwikkeling. Om
erachter te komen wat die invloedsfactoren zijn, willen we van jullie
weten welke trends op het gebied van onderzoek, technologie en
bestuurlijke politieke windrichting verandert de toekomst van research
data management en software management op dit moment? Denk aan open
science versus kennisveiligheid, want met de geopolitieke situatie
verandert dat ook nog steeds. Maar jullie hebben zelf ook al genoemd AI,
dat een invloed zou kunnen hebben, of Chat GPT of CodeGPT, voor de
reproduceerbaarheid van documentatie van wetenschappelijke code en EOSC,
wat is het, European Open Science Cloud tools. Dat is wat jullie hebben
aangegeven, Marcel en Meron. In andere woorden, welke technologische,
economische ontwikkeling of politieke besluiten zijn nu aan de gang die
de koers van research data management en research software management in
de nabije toekomst gaat bepalen? Mag ik Meron het woord geven? Want die
stak zijn hand net op.

*Meron:* Dank je. Ja, dat was gedeeltelijk in reactie. Waar ik een heel
klein beetje terugkoppeling naartoe zou brengen, is dat al deze nieuwe
ontwikkelingen niet alleen van belang zijn voor open science, maar ook
daadwerkelijk een onderzoeker helpen. Hoewel het misschien op eerste
hand lijkt als idealisme en papierwerk en je moet weer een nieuwe
workflow aanleren, maar op de lange termijn heeft het\... Uit allerlei
hoeken is bewezen dat het je meer rust en een betere workflow geeft. Al
deze nieuwe initiatieven en stromingen, die natuurlijk nog iet wat
onzeker zijn, maar wel duidelijk de richting op duwen van het
makkelijker maken. Neem ondersteuning in een Chat GPT, CoGPT. Maar er
zijn veel meer AI-tools die zowel in de start-upwereld als daarbuiten
opgepakt worden en in een stroomversnelling komen. Dat zal dus nog
enkele jaren duren, maar dat moet, als het goed is, het veel makkelijker
maken om aan de slag te gaan.

*Maurice:* Dus jij zegt dat vooral het sociale aspect, de verwachting
van de onderzoeker is dat de gebruiksvriendelijkheid ontzettend hoog
moet zijn om überhaupt hier iets mee te gaan doen, omdat alle tools en
appjes die op de telefoons werken, die zijn ook gebruikersvriendelijk.
Dus waarom verwachten we dan dat voor research data management en
research software management dat veel te ingewikkeld zou moeten zijn?
Mensen hebben betere dingen te doen dan zich helemaal op het codeniveau
af te dalen, maar willen op een gebruikersniveau eenvoud. Dat is één
aspect, wat je zegt, wat je nu ziet. Dat de verwachtingen van de
gebruikers van de gebruikersvriendelijkheid heel hoog is.

*Meron:* Ja, dat klopt. Dat is natuurlijk al langer aan de gaande met
low-code no-code bewegingen, waarbij je niet meer diep in de code hoeft
te zitten. Maar het is ook, als je wel diep in de code zit, is het
adopteren van goede practices, zowel goed voor de stabiliteit van wat je
produceert aan code of software als een verbetering om recognition award
erkenning te krijgen voor wat je produceert. Daar moet vanuit met name
de reward, de beloning nog wel wat gebeuren. Maar daar zijn allerlei
bewegingen die langzaam aanduwen dat hier inderdaad meer beloning voor
komt en waardoor het dus ook kan groeien.

*Maurice:* Dat is mooi gezegd. Dus aan de ene kant
gebruiksvriendelijkheid. Andere kant, als je daar effort in stopt, wil
je daar ook voor beloond worden. Tools die kunnen daar misschien bij
helpen met, wat je al zei, de CoGPT voor\... Je schrijft een stukje
code, maar je hebt geen zin om documentatie te schrijven. Je laat GPT de
documentatie schrijven van de code die je hebt geproduceerd. Dat is
ongeveer dat idee en dan vervolgens wil je daar ook voor beloond worden.
Tim, wat voor ontwikkelingen zie jij?

*Tim:* Hoeveel wil je er hebben, Maurice?

*Maurice:* Begin maar bij eentje.

*Tim:* Eén van de belangrijkste dingen die ik zie is, naast de dingen
die je al genoemd hebt zoals AI bijvoorbeeld, is het data-eigenaarschap.
Je ziet steeds meer dat vanuit een reguleringsperspectief dat geëist
wordt, dat data-eigenaarschap bij subjecten ligt waar het over gaat.
Software in beweging, wordt dat vaak genoemd. Je ziet het vooral in de
medische hoek, zie je dat nu heel erg met de persoonlijke
gezondheidsomgeving of met mij-achtige omgevingen waar je als individu
zelf de controle hebt, over wie wat met jouw data mag. Zeker voor mensen
die onderzoek doen in een onderzoekscontext zou dat nog wel een flinke
stap kunnen zijn, als je daar aan moet sluiten op dat soort omgevingen
of dat soort bewegingen om eigenaarschap bij een subject te kunnen laten
liggen.

*Maurice:* Dus mag ik daarin samenvatten dat je algoritmes naar de data
toe brengt, zodat je de data niet hoeft te ontsluiten. Is dat een
beweging die je bedoelt?

*Tim:* Ja, dat is één van de oplossingen die je nu al ziet gebeuren, hè.
Dat we inderdaad onze algoritmes, onze software naar de data toe
brengen. Maar je krijgt dan ook de vraagstuk van wat voor rechten heeft
iemand van wie je die data gebruikt? Kan iemand dat recht inzien of
inzien wat er met die data gebeurt? Kan iemand het recht om te gebruiken
intrekken en hoe ga je daar dan mee om? Zeker vanuit een data provenance
perspectief. Dus ook gewoon kunnen laten zien waar je die data vandaan
hebt gehaald. Dat is weer een andere benadering dan dat we nu hebben.
Voor mij gaat dat dingen ook wel weer een stukje complexer maken. Wel
eerlijker, fairer, maar complexer.

*Maurice:* Wat maakt dat complexer?

*Tim:* Het maakt het complexer omdat je met veel meer partijen eigenlijk
zaken aan het doen bent en rechten moet kunnen afstemmen. Dus je hebt
het niet meer over zaken doen met één partij die eigenaar is van een
dataset, maar je hebt het over individuen waar je eigenlijk zaken mee
doet. Hier hebben we ook gewoon nog niet een heel goeie structuur voor,
volgens mij.

*David:* Wordt daar bijvoorbeeld ook landelijk naar gekeken, in
wetgeving bijvoorbeeld?

*Tim:* Als we het hebben over wetgeving, die zit voornamelijk in de
medische hoek nu. Ik geloof niet dat het echt in de onderzoekshoek
al\... Daar heb je de algemene, hoe heet het, AVG-wetgeving, maar ik
geloof niet dat het nu al voor het gebruik van dat soort gegevens in
onderzoek specifieke toepassingen zijn.

*Maurice:* Ik probeer te begrijpen wat je zegt, Tim. In de medische
wereld heb je, ook in de onderzoekswereld, dat je consent forms gebruikt
naar individuen om te zeggen van dit gebeurt er met de data die jij aan
mij hebt geleverd. Op dat niveau zeg je dat er rechten moeten worden
afgesproken dat iemand soeverein is, zelf soevereiniteit heeft over zijn
eigen data die die ter beschikking stelt. Is dat de beweging die jij
ziet echt op individueel niveau? Dus ik ben de consument, ik vul
verschillende vragenformulieren in en ik heb zicht op, in een papier wat
ik dan bijhoud, waar ik overal mijn data heb achtergelaten en waarbij,
als er een verwerking plaatsvindt, dat ik daar op al die verwerkingen
akkoord moet geven.

*Tim:* Ja, inderdaad. Dat is ook veel digitaler ingestoken. Kijk, een
consent form dat kan een heel simpele invulling zijn. Die doe je ook\...
In veel gevallen is dat iets, je doet het aan het begin van een
onderzoek, maar je ziet niet meteen automatisch terug wat ermee gebeurt.
Dat is net wat voor afspraken, wat voor proces een onderzoeker volgt.
Als je kijkt naar die medische wereld, je hebt er veel meer controle
over wat er dan gebeurt met je data. Je kan ook rechten weer intrekken
dan bijvoorbeeld. Dus inderdaad, de soevereiniteit, zoals je dat
beschrijft, Maurice, die ligt dan bij de persoon zelf.

*Maurice:* Natuurlijk wat je zegt, er zijn verschillende
dataleveranciers, je hebt ook overheden. We hebben nu de hele beweging
over kennisveiligheid, over data die bijvoorbeeld met raketinstallaties
en hypersonische raketten en noem maar op. Al die technologieën die
mogelijk de staatsveiligheid in gevaar kunnen brengen, dat die ook onder
dat kader vallen. Dat er een partij is die daarover moet beslissen wat
ermee gaat gebeuren, die de instellingen in ieder geval overstijgt. Heb
je nog meer? Want je zei, Tim, dat je er nog veel meer voorbeelden hebt.
Maar misschien moeten we ook even naar Marcel toe, want misschien zit
die te popelen om ook iets te noemen.

*Marcel:* Zeker, ik zit ontzettende popelen om iets te noemen. Even iets
naar een hoger abstractieniveau namelijk samenwerking. De enorme
vergroting van de mogelijkheden tot samenwerking die onderzoekers hebben
door verdergaande digitalisering van de samenleving en van
netwerkisering van de samenleving en ook voor netwerkisering van
onderzoeksomgevingen. Dat maakt het voor onderzoekers\... Zij krijgen
veel meer mogelijkheden om binnen instituten, maar ook over instituten
heen, over disciplines heen, internationaal, publiek-privaat samen te
gaan werken binnen onderzoeksthema\'s om data van erfgoedinstellingen te
gebruiken. Dat vergroot wel echt de reikwijdte, denk ik, van
onderzoekers. Het vergroot de reikwijdte van onderzoek en vraagt ook om
andere infrastructuren, om veel bredere infrastructuren. Je noemt dit
vaak virtuele onderzoeksomgevingen en dat is wel een ontwikkeling die
echt in gang is gezet, naar mijn idee, door vergaande vernetwerkisering
van omgevingen.

*Maurice:* Ik probeer het een beetje voor mezelf helder te krijgen. Dus
je zegt: de toenemende mate waarin onderzoekers samenwerken. Marcel,
sorry, volgens mij was je gaan praten, maar je internetverbinding is
onstabiel.

*Marcel:* Oké, excuus. Ik denk dat die manier van samenwerking ook nog
wel versterkt wordt vanuit bijvoorbeeld iets als het programma Open
Science. Dat die ontwikkeling richting Open Science ook weer zorgt voor
meer en beter delen van onderzoeksresultaten en onderzoeksdata, waardoor
er ook weer verdere versnelling komt in onderzoek. Wat vervolgens weer
vraagt om stevigere onderzoeksinfrastructuren en heldere afspraken.

*Maurice:* Marcel, ben je nog gaan praten?

*Marcel:* Nee, dat was ik niet.

*Maurice:* Oké. Ik probeer het even samen te vatten, maar ik heb
gehoord: de toenemende mate waarin er samen wordt gewerkt. Binnen
verschillende virtuele omgevingen wordt er ook steeds meer gezamenlijk
data opgebouwd. Dat is een ontwikkeling die jij op dit moment ziet
gebeuren. Vat ik dat zo goed samen?

*Marcel:* Ja, dat klopt. Wat ik daaraan toe wil voegen is dat er ook
veel meer data vanuit andere partijen beschikbaar komt.

*Maurice:* Juist.

*Marcel:* Private partijen maar bijvoorbeeld ook erfgoedinstellingen.
Dus het wordt ook veel makkelijker om data van een nationale
\[onhoorbaar 00:25:36-00:25:36\] een Instituut voor Beeld & Geluid te
gebruiken in een onderzoek.

*Maurice:* Dus de bestaande data die eerst gewoon data an sich was,
wordt nu opeens onderzoeksdata.

*Marcel:* Ja.

*Maurice:* Wordt het onderzoeksdomein ingetrokken. Tim, je hebt je hand
omhoog.

*Tim:* Ja, Maurice. Marcel noemde dit wel, maar in je samenvatting had
je het nog niet genoemd. Maar één van de dingen waar ik het meest op
hoop als we het hebben over samenwerking is standaardisatie en een soort
ontwikkeling van de facto standaard tools. Dat we daar steeds meer naar
toe gaan werken, naar een soort van common toolset en common
afsprakenset of in ieder geval een soort van kernafsprakenset, die we
kunnen gebruiken om meer te digitaliseren en ook werk van onderzoekers
makkelijker te maken. Normaalstandaarden lukt natuurlijk nooit helemaal.
Maar goed, dat we dat wel een stapje verder kunnen brengen.

*Maurice:* Dat is wat je nu hoopt of wat je nu ziet gebeuren?

*Tim:* Dit is een ontwikkeling, die speelt al eigenlijk langer en het
gaat elke keer een stapje voor stapje gaat dat verder. Je merkt wel nu
dat met\... Er wordt best wel veel geïnvesteerd nu vanuit het nieuwe
Horizon-programma op EU-niveau en ook binnen Nederland met
Digitaliseringsimpuls, of Npuls, in opzetten van nieuwe gedeelde
digitale voorzieningen voor de onderwijs- en onderzoeksector. Dus ik
denk dat er echt een beweging aan zit te komen de komende paar jaar, dat
we gedeelde tools, gedeelde afspraken, gedeelde standaarden gaan
ontwikkelen. Maar het staat nog wel een beetje.., Ik wil niet zeggen in
de kinderschoenen, want dit loopt al jaren. Maar we zijn er nog niet.

*Maurice:* Dus de ontwikkeling gaat een beetje langzamer dan je had
gehoopt. Dit kunnen we natuurlijk ook wel plaatsen bij de
aantrekkingskracht van de toekomst. Ideaalbeeldje, ideaalplaatje, daar
gaan we zo meteen naartoe, maar Meron heeft nog even een vraag. Dat is
de laatste en dan gaan we dan door naar de aantrekkingskracht van de
toekomst. Maar Meron, je hebt je hand omhoog. Had je nog een toevoeging?

*Meron:* Een hele korte toevoeging. Dit gaat over\... Gerelateerd aan
het teamverband of het meer netwerken. Maar daarbij wil ik juist meer
pushen naar teamverband eigenlijk, omdat\... Momenteel is onderzoek
natuurlijk niet een individuele exercitie. Maar de rollen die zich nu
uitoefenen zijn meestal wel een PhD die zijn ding doet, een postdoc die
al dan niet met een paar anderen wat doet. Maar om daar bijvoorbeeld een
research software engineer met een specifiek takenpakket deel van te
maken en dat in het hele instituut op te nemen en daar beloning voor te
geven en mogelijkheid en subsidiëring voor te geven, daar mist nog een
klein beetje momenteel. Dat zou op een nationaal vlak kunnen, dat kan
ook binnen een instituut zelf, maar daar valt zeker nog iets te winnen.

## Aantrekkingskracht van de toekomst

*Maurice:* Ik hoor het inderdaad, Meron, dat we richting recognition
rewards, de team science en de deelgenoten, die in het wetenschappelijke
kenniscreatieproces zitten, beloond moeten worden voor elk tussenstapje
wat gemaakt moet worden. Ik denk dat dat ook wel heel goed past bij het
tweede deel, de aantrekkingskracht van de toekomst, want daar ga ik nu
eerst naartoe. Na het heden hebben we natuurlijk de toekomst. Er is een
aantrekkingskracht van de toekomst. Wat is het meest dominante beeld of
visie die jullie voor research data management en research software
management voor ogen hebben? Want dit beeld gaat ons helpen om de weg er
naartoe te vinden, hè, door die mist en die lamp die dan schijnt door de
mist heen. Daar moeten we in ieder geval naartoe. Dus wat zou research
data management en research software management dienstverlening in 2030
moeten worden geboden aan een universiteit? Hoe zou dat eruitzien? Ik
hoor inderdaad recoginition en rewards. Dus misschien hebben jullie daar
een gezamenlijk beeld van hoe dat eruit gaat zien. Mag ik bij Marcel
even beginnen?

*Marcel:* Ik weet niet of dat direct een gezamenlijk beeld is. Ik denk
dat er veel beelden kunnen zijn van hoe dat eruit zou kunnen zien. Maar
als je dat bekijkt vanuit dienstverlening, vanuit research data support,
dan is het, denk ik, van heel groot belang dat we ervoor gaan zorgen dat
research data management zo makkelijk mogelijk gemaakt gaat worden voor
onderzoekers. We zitten nu nog een beetje in een situatie waarbij we te
maken hebben met een versnipperd landschap. We hebben allerlei
voorzieningen voor het opslaan en delen en archiveren van
onderzoeksdata. Daar ontwikkelen we allerlei hulpmiddelen voor. We
hebben te maken met AVG-kwesties waar we ondersteuning op bieden.
Onderzoekers moeten allerlei verschillende formulieren invullen in hun
research lifecycle, tijdens dat ze onderzoek doen. Ze moeten een data
managementplan maken. Ze moeten informed consent formulier invullen.
AVG-registratie doen. Ze moeten langs de ethische toetsingscommissie.
Dat zijn eigenlijk allemaal administratieve handelingen die afleiden van
het daadwerkelijk doen van onderzoek, maar die wel heel erg noodzakelijk
zijn. Daar hadden we het al eerder over, omdat de funder erom vraagt om
ervoor te zorgen dat onderzoeksoutput betrouwbaar, reproduceerbaar is en
transparant is. Het is, denk ik, van belang dat we dit zoveel mogelijk
proberen te automatiseren. Standaardiseren is niet een woord wat ik hier
zou willen gebruiken. Maar daar waar we dit kunnen automatiseren en
makkelijker kunnen maken voor onderzoekers, is dit een hele goeie stap
voorwaarts.

*David:* Ik hoor twee dingen, eigenlijk twee bewegingen. Eén is dan: het
moet van de beleidsmakers en die hebben allemaal vervelende eisen en
daar gaan we ze bij helpen om daaraan te kunnen voldoen. En anderzijds,
zoals Tim net schetste, gaat het over goede samenwerking, onderzoek
beter maken. Nou is het natuurlijk voor onderzoekers die tweede is dat
echt inhoudelijk interessanter. Hoe kunnen we\... Een universiteit is
een onderzoeksomgeving waar eigenlijk die tweede, dus de
dienstverlening, dat onderzoekers echt hier inhoudelijk profijt van
hebben. Wat is daarvoor nodig aan de universiteit?

*Marcel:* Naar mijn idee is het wel echt nodig dat we ondersteuning zo
makkelijk mogelijk maken, dat het minder tijdrovend is dan dat het nu
is. Want het zijn eisen die funders stellen. Het zijn overigens vaak
heel terechte eisen. Ze kunnen als vervelend ervaren worden, maar ze
zijn natuurlijk wel vaak heel terecht, zeker als we onderzoek echt
verder willen brengen. Dus voor mij zit de crux er echt in dat we het zo
makkelijk mogelijk maken voor onderzoekers en dat er zo min mogelijk
drempels zijn om die zaken te doen, die ervoor zorgen dat onderzoeksdata
zo goed mogelijk beheerd wordt.

*Maurice:* Ik zie dat\... Jouw toekomstbeeld is eigenlijk dat ter
ondersteuning van onderzoekers, dat onderzoekers er eigenlijk helemaal
niks van hoeven te merken. Dus dat, ik noem het even immersive support,
dat onderzoekers zich alleen maar met het onderzoeksprocessen
bezighouden en dat alle randzaken onder water worden gerealiseerd. Is
dat jouw visie?

*Marcel:* Niet helemaal, want ik vind wel dat onderzoekers wel een
verantwoordelijkheid hebben om, wanneer ze beginnen aan een onderzoek,
goed na te denken over welke onderzoeksdata ga ik creëren, verzamelen?
Hoe ga ik dat delen? Hoe ga ik überhaupt om met mijn onderzoeksdata en
onderzoeksobjecten? Dus daar ligt zeker een verantwoordelijkheid bij die
onderzoeker. Maar alle processen die daar aan ten grondslag liggen, die
moet je zo makkelijk mogelijk maken, zo veel mogelijk automatiseren daar
waar je het kunt automatiseren. Het ontslaat de onderzoeken niet van een
verantwoordelijkheid.

*Maurice:* Oké. Tim, heb jij daar iets aan toe te voegen? Ben je het
eens met dit beeld?

*Tim:* Grotendeels ben ik het met Marcel eens. Ik ben heel blij dat ie
de toevoeging doet dat een onderzoeker hier nog een eigen
verantwoordelijkheid in heeft. Maar dat had ik ook niet anders verwacht
van Marcel. Ik denk wel één ding dat ik eraan zou willen toevoegen: waar
we nu zitten met resource support, is RDM een relatief reactief ding.
Een onderzoeker die gaat zelf aan de slag met datamanagement, weliswaar
getriggerd in veel gevallen door eisen vanuit buiten, maar die neemt er
het initiatief voor. Ik denk dat ook in veel gevallen dingen veel meer
proactief gedaan worden, doordat je met virtual assistentachtige tools
gaat werken, die op het moment dat jij in een bepaalde stap in een
proces zit vanzelf bijvoorbeeld met data cleaning stappen gaan werken,
of dat ze bepaalde data automatisch omzetten in standaardformaat voor
publicatie of iets dergelijks. Dat niet meer alles in handen van een
onderzoeker hoeft te liggen. Je wil wel de controle bij de onderzoeker
houden, want een onderzoeker moet weten wat er gebeurt. Een onderzoeker
moet weten hoe data wordt getransformeerd of hoe het wordt behandeld als
je het naar buiten, als je het gaat publiceren bijvoorbeeld. Maar dat je
daar wel veel meer door intelligente tools kan worden gedaan. Dat gaat
volgens mij nog een stapje verder dan puur automatiseren van stappen,
omdat je echt een stukje AI-assistentachtige rol gaat inbouwen die
onderzoekers daar een stukje werk uit handen neemt.

*David:* Ik hoor dus de ondersteuning en het onderzoeksproces, misschien
ook het opslaan van data en dat converteren naar een deelbare standaard,
bijvoorbeeld. Dat is dan onderzoekers helpen. Wat moet er gebeuren dat
onderzoekers echt elkaars data ook gaan gebruiken, misschien ook
wereldwijd? Hoe kan goed research data management die samenwerking
versterken tussen onderzoekers?

*Tim:* Wat je met research data management, goed research data
management, doet, je maakt het mogelijk. Je maakt het mogelijk doordat
je data is goed beschreven, dus het is vindbaar. Je software is goed
beschreven, dus je onderzoek is reproduceerbaar. Je hebt
standaardsoftware gebruikt en ook goed uitgewerkt hoe je dat hebt
gedaan. Dus je interoperabiliteit is geregeld. Dat is de faire
principes, hè. Je maakt een hoop mogelijk om dat te gaan doen. Of het
vervolgens ook gebeurt, is een tweede. Daar zit je ook eigenlijk veel
meer te kijken naar wat zijn de incentives voor een onderzoeker om
bepaald soort onderzoek te gaan doen? Dat is eigenlijk geen research
data management meer waar je het dan volgens mij over hebt, maar je hebt
het over wat voor soort onderzoek wordt beloond. Dus dan zit je weer in
die recognition- en rewardshoek zit je te kijken. Sommige soorten
onderzoek moet\... Het hergebruik van een dataset moet ook iets
opleveren voor een onderzoeker.

*Maurice:* Ik heb hier even staan: standaardisatie van
data-interoperabiliteit maakt het mogelijk om sneller samen te werken,
maar daar moeten we ook wel voor worden beloond. Dus een
toekomstscenario van jou is dat je graag dat ziet dat er standaardisatie
van data-interoperabiliteit is, plus dat onderzoekers om die effort te
maken om naar die standaarden toe te werken, dat ze daar ook wel
degelijk voor worden beloond. Hetzij in financiële beloning of met leuke
stickers of, hoe heet dat ook weer, edubadges of de microcredentials.
Marcel\... Sorry, Tim.

*Tim:* Ik zou het niet in de hoek van financiële of edubadge beloning
willen gooien. Waar wordt een onderzoeker vaak op afgerekend, dat is,
hoe noem je dat, de publicatiedruk die hij nu heeft. Dat is hetgeen wat
je als onderzoeker bepaalt of je je werk goed doet. Maar dat is wederom
het stukje wat in recognition en rewards al vaak besproken wordt. Het
feit dat je je data goed hebt gedocumenteerd, dat je het fair hebt
gemaakt en dat daarna een andere onderzoeker dat ook gebruikt, dat moet
net zoveel wegen als het feit dat jij een publicatie hebt gemaakt met
behulp van die data. Als je niet die twee dingen regelt, dan kan je een
edubadge uitdelen wat je wil, maar het levert een onderzoeker
uiteindelijk niks op. Dat is iets wat je niet binnen RDM an sich kan
regelen. Dat is niet een dienstverlening die wij kunnen opzetten. Dat is
iets waar je als universiteit en als UNL en op Europees niveau eigenlijk
andere beloningsstructuren, andere promotie-, carrièretrajecten voor
moet opzetten.

*David:* Meron, op het gebied van research software management, wat zou
jij het liefst\... Je bent nu echt veel aan het opzetten en
inventariseren. Wat als het aan jou ligt? Wat zie jij voor je wat er in
2030 wordt aangeboden aan de universiteit op jouw onderwerp?

*Meron:* Daar is inderdaad heel erg veel gaande momenteel en er is
waanzinnig veel overlap met data en fair data. Er zijn alleen wat
kanttekeningen en aanpassingen die je daar toch wel mee moet nemen en
rekening mee moet houden. Wat in ieder geval zo is, los van zo makkelijk
mogelijk maken, is momenteel bij het fair software ontwikkelen toch een
verandering in de manier van het doen van het werk van veel
wetenschappers nodig. Die is niet reusachtig, maar dat is wel net wat
nieuwe technologieën leren, zoals versiebeheer en de juiste manier
vervolgens het naar publicatie brengen, relatief simpel, maar iets wat
nog onder de aandacht moet komen. Daarvoor komt meteen een belangrijk
punt waar het daar verder naar toe moet gaan, is dat er voldoende
digitale en computationele literacy gecreëerd wordt bij zoveel mogelijk
onderzoekers. Dit is naar mijn idee anders dan het gevoel hebben dat je
papierwerk doet. Want als je eenmaal op deze manier van werken jezelf
hebt aangeleerd, wordt het veel prettiger, geeft het je veel meer rust
om op die manier te werken. Daarbij kan ik uit eigen ervaring spreken,
moet ik zeggen. Dit is natuurlijk aan de kant van de onderzoeker die
iets moet doen. Verder is dan support voor onderzoekers op het onderwerp
open research software en fair research software nog iets waar heel veel
groei in nodig is en waar een ondersteuningsstructuur voor opgezet moet
worden, waar de komende jaren ingegroeid zou moeten worden. Daar kunnen
we nationaal heel veel van elkaar leren en heel veel oppakken, omdat het
allerlei domeinspecifieke uitdagingen heeft. Zijn de TDCC\'s hier ook
bij van belang en het uitwisselen van expertise tussen de
universiteiten. Dat zijn we nu ook al langzaam op aan het zetten, maar
dat heeft nog best wat groei nodig.

*David:* We hebben heel vaak over gewenst. Dat was de vraag: wat zijn
nou echt gewenste toekomstbeelden? Dat is natuurlijk ook AI en zeker de
toekomst van ChatGPT, maar ook de verkiezingsschandalen, AI in data en
persoonlijke data is steeds een groter onderwerp geworden, ook van de
dystopische toekomst. Hebben jullie ook voor ogen wat er zou kunnen
gebeuren als we zelf niet de controle nemen en waar het eventueel fout
zou kunnen gaan?

*Tim:* Als je daar weer bij AI specifiek blijft hangen, dan zijn er
natuurlijk 1000 dingen die er fout kunnen gaan. Je hebt daar eigenlijk
wel een soort wapenwedloop tussen AI-tools om fake content te genereren
en AI-tools om die te herkennen. Dat is een beetje de meest
oppervlakkige horrorscenario dat je al hebt. Maar volgens mij zijn er
nog wel meer horrorscenario\'s die voor een VU specifiek relevant zijn.
We zeggen altijd: we zijn een maatschappelijk georiënteerde
universiteit. Dat brengt ook bepaalde verantwoordelijkheid met zich mee
in hoe je besluiten neemt binnen een organisatie, hoe je met data omgaat
of hoe je dingen opzet en waar je dus ook een bepaalde\... Ik probeer
niet te vage woorden te gebruiken, maar je moet weten op basis waarvan
je je besluit neemt. Je moet weten wat er gedaan wordt met bepaalde\...
met AI-algoritmes bijvoorbeeld, die besluiten iets wel te doen of niet
te doen, wel toe te staan, niet toe te staan. Als je zegt dat jij een
diverse, open, eerlijke universiteit bent, maatschappelijk betrokken
universiteit bent, daar zit wel een risico in natuurlijk.

*Maurice:* Zit er ook een risico in dat we alle data maar openbaar
moeten maken of in ieder geval digitaal gaan opslaan en op het internet
wordt geplaatst? Ook al zeggen we dat het niet toegankelijk is,
restricted access wordt het genoemd. Zit daar nog een risico in? Ik zag
Meron een hand omhoog steken. Ik weet niet of dat ermee te maken heeft,
maar\... Marcel.

*Marcel:* Daar zit wat mij betreft wel een risico in. Dat is een beetje
een stokpaardje van mij en dat heeft te maken met het woord
duurzaamheid. Je kunt kijken naar duurzaamheid in de zin van digitale
duurzaamheid, de duurzaamheid en de langetermijnbeschikbaarheid van
onderzoeksdata, maar je kunt ook woord duurzaam plakken op environmental
sustainability. Ik denk één van de dingen waar we nog echt niet goed
zicht op hebben en waar we naar mijn idee ook nog niet voldoende goed
over nadenken is: hoe gaan we om met het toegankelijk maken, het
digitaliseren toegankelijk maken via netwerken op plaatsen van
onderzoeksdata gerelateerd aan de klimaatcrisis en energietransitie waar
we mee te maken hebben? Ik denk dat we als tegenbeweging tegen alles
maar open en toegankelijk en beschikbaar maken, ook wat wel kritischer
moeten op wat maken we dan open, beschikbaar, 24-7 toegankelijk? Moeten
dat alle versies van al je onderzoeksdata zijn? Moeten we daar niet wat
kritischer op zijn? Moeten we meer aan data cleaning doen? We moeten,
denk ik, ook meer aandacht besteden aan het optimaliseren van opslag. Ik
denk dat dat ook echt wel een belemmerende factor kan gaan worden voor
toegankelijkheid en samenwerking. Tegelijkertijd liggen daar, denk ik,
ook wel kansen om dat veel beter te doen. Maar we zullen er wel kritisch
naar moeten kijken, vind ik.

*Maurice:* Ja, dat snap ik. Meron, jij had net een hand omhoog. Vertel.

*Meron:* Eigenlijk sluit dat precies aan bij wat Marcel zei en wat
Marcel zei over de milieuduurzaamheid, dat wilde ik zeker ook aansnijden
hierbij. Met name gerelateerd aan wat nu juist groeiende is en nog nodig
is bij software en initiatieven om te zorgen dat de code van een
onderzoeker overal op ieder moment nog eens gedraaid kan worden. Dit
vraagt een heleboel ontwikkeling en is relatief zwaar, omdat dat moet
kunnen rekenen. Je moet die platforms de lucht in krijgen en dat gebeurt
nu omdat dat voor Open Science goed is. Maar dit vraagt ook een heleboel
belasting op elektriciteit, op hitte die geproduceerd wordt, op al die
servers die moeten draaien. Dit is voor data en software evengoed een
zwaar ding. De vraag is: moeten we dat dan bijvoorbeeld altijd aan
blijven bieden? Moet dat op aanvraag kunnen? Hoe kunnen we ervoor zorgen
dat het én open én beschikbaar is, maar dat we niet over onszelf heen
vliegen met ons idealisme en het belang van de wereld daarin verliezen,
zal ik maar zeggen.

*Maurice:* Ik begin het inderdaad te begrijpen, Marcel, ook nu Meron dit
heeft gezegd, dat je die duurzaamheid op het ecologische vlak\... Moeten
we alles wel willen bewaren? Al die disks die blijven spinnen om de data
maar te bewaren om het te bewaren. Inderdaad, zouden we daar een soort
opschoonacties die we bij de bibliotheek eigenlijk ook met boeken doen,
ook dat voor data moeten gaan doen? Wat we ook bij archieven doen, hè.
Er worden selecties gemaakt om ervoor te zorgen dat het niet overloopt.
Dus de selecties die worden gemaakt, worden natuurlijk misschien gemaakt
in een bepaald tijdsbeeld en er worden misschien dingen weggegooid die
historici misschien interessant hadden kunnen vinden. Maar wat je zegt,
dat is een dilemma.

*Marcel:* Dat is altijd een dilemma. Dat is in ieder tijdperk een
dilemma. Ik herinner mij, toen ik bij de KB me bezighield met het
archiveren van Nederlandse websites en ik aan onderzoekers vroeg: welke
website zou je nu willen archiveren, was standaard het antwoord: alle
websites. Want ik weet nu niet welke keuze ik straks voor mijn onderzoek
maak. Tegelijkertijd is alles gewoon niet mogelijk en moeten we daar
gewoon kritisch over nadenken. Zeker als je bedenkt hoeveel energie en
hoeveel water bijvoorbeeld een groot datacentrum opslokt, dan kom je bij
dystopische hoeveelheden eigenlijk. Ja, daar moet je echt goed over
nadenken.

*Maurice:* Ik wou er niet over beginnen, maar er zijn ontwikkelingen
natuurlijk, waarbij je dus dataopslag in DNA hebt natuurlijk.

*Marcel:* Absoluut.

## Gewicht van het verleden

*Maurice:* DNA is natuurlijk wel een hele goeie. De dubbele helix is
natuurlijk een hele goede databewaarplaats. Er zijn ontwikkelingen die
daar mee bezighouden, dat misschien wel verbetering kan plaatsvinden
voor herarchiveringsopslag. Het uitlezen van zulk DNA, dat kost
natuurlijk wel weer wat meer energie. Dat zijn die ontwikkelingen die
dat dystopische toekomstbeeld een beetje kunnen bijbuigen. Maar omdat we
nu al een beetje zitten te zeggen van oké, wat we allemaal meenemen uit
het verleden, al die versies die moeten bewaard worden, is dat niet een
mooi bruggetje naar het volgende stuk over het gewicht van het verleden,
de blok beton wat je meesleurt, de remmende factoren die veranderingen
verhinderen om dat toekomstbeeld te realiseren? Ik heb een voorzetje
gemaakt, maar hebben jullie nog meer voorbeelden daarvan? Wat we nu zien
als vooruitgang, wat straks dan ons kan belemmeren in de vooruitgang?

*Marcel:* Als ik even voortborduur op waar het net over hadden, dan is
dat toch die wens en eis bijna - niet alleen binnen de academische
wereld, maar misschien ook wel binnen de hele samenleving - dat alle
kennis, alle informatie beschikbaar is en wel nu en wel snel. Misschien
moet je die wens in de toekomst wel ook een klein beetje bijstellen. Je
zou kunnen zeggen: het is er wel, maar het is niet binnen drie
nanoseconden voor je beschikbaar. Je moet daar even iets langer op
wachten, maar het is er wel. Dus misschien is het ook vaak een kwestie
van verwachtingen bijstellen.

*Maurice:* Maar dan komen we ook weer terug op de
gebruiksvriendelijkheid daarvan, natuurlijk. Dat zit dan een beetje in
gespannen voet met\... Onderzoekers verwachten inderdaad dat het snel
beschikbaar moet zijn en dat het dan vervolgens dat het ook wel weer
afremt. Maar je hebt gelijk.

*Marcel:* Het heeft ook te maken met verwachtingsmanagement en je kunt
dit, denk ik, heel goed uitleggen waarom iets niet binnen drie
nanoseconden beschikbaar is, maar even iets langer duurt.

*Maurice:* Zeker. Anderen nog? Economische factoren misschien, geld?

*Tim:* Als je het daarover gaat hebben, de manier waarop onderzoek
gefinancierd wordt, heel erg projectmatig gezien, helpt niet bij aan
duurzaamheid creëren, denk ik. Je richt op het kortetermijnoplossingen.
We moeten tijdens een onderzoek moeten we dingen op orde hebben. Tijdens
een onderzoek moeten we dingen geborgd houden. Maar je merkt nu al dat,
zeker als het gaat om langere-termijnopslag bijvoorbeeld of langere
termijn toegankelijk houden van data of bruikbaar houden van software,
zoals Meron net aangaf, daar zit niet meteen een goeie
financieringsstructuur voor. Of liever gezegd, dat kan je niet makkelijk
ophangen aan een specifiek project, zeker als je gaat kijken naar de
data die we veel meer zouden willen hergebruiken.

*Maurice:* Dus de financieringsstructuur van het onderzoek is niet
geschikt voor duurzame opslag van data en runtime environments\...

*Tim:* Ja.

*Maurice:* Wie hebben we nog niet gehad? We hebben ze eigenlijk allemaal
een beetje gehad, hè? Volgens mij zijn dat de dingen die een beetje in
de weg staan. Is er ook nog een politiek beeld, een politieke winst die
nog in de weg staat? In ieder geval, wat ik nog kan verzinnen is
onderzoekers die nu nog gebaat zijn bij het waarderen en erkennen in het
oude systeem, dat die nu vaak hoogleraren zijn en niet echt
geïnteresseerd zijn in die verandering misschien. Om dat te doorbreken
is wat moeilijker. Dat is wat ik nog kan verzinnen. Als je kijkt naar
het technologisch vlak, hebben we nog wat? We hebben misschien met de
oude technologieën te maken die nog achter ons aan slepen. Hoe gaan we
daarmee om? Bijvoorbeeld nu hebben we dus Joda geïnstalleerd, maar de
eerstvolgende technologie die klopt nu wel alweer aan de deur. Zijn we
klaar ervoor om zo makkelijk te kunnen migreren met nieuwe
data-infrastructuren. Is dat nog een zaak waar we ons nog niet goed op
aan hebben gepast? Nu moet ik zeggen dat Joda, volgens mij, daar zit een
infrastructuur, middle ware, achter, waarbij de opslag van data geen
probleem meer is. Maar zit ik in die richting goed te denken, dat daar
een rem op zit?

*Marcel:* Ik weet niet of je dat een rem moet noemen, maar ik denk dat
dat altijd het geval is. Je ontwikkelt infrastructuur, je ontwikkelt
structuren en tegen de tijd dat je die goed en wel aan het gebruiken
bent, staan er nieuwe technieken en nieuwe infrastructuren aan de deur
te kloppen. En dat het altijd even duurt voordat je die dan weer kunt
opnemen en kunt gaan migreren naar nieuwe structuren. Ik denk dat we
daar eigenlijk altijd wel een beetje achterlopen. Wat ook weer niet zo
heel erg is, denk ik. Op dit moment kan Joda alles wat we nu wensen.
Misschien zijn er nog wel wat specifieke wensen. Over twee jaar hebben
we nieuwe wensen en dan gaan we ontwikkelen op basis van die nieuwe
wensen.

*Maurice:* Tim, misschien heb jij nog een toevoeging over die
standaarden misschien, want nu hebben we standaarden maar over volgend
jaar hebben we betere standaarden. Ik weet niet. Of misschien heb je
andere toevoeging?

*Tim:* Zeker. Wat je eigenlijk wilt doen, en dit is niet eens
onderzoeksspecifiek, je ontkoppelt de manier waarop je data behandelt en
waarop je systemen behandelt en voor allebei wil je standaarden hebben.
Op die manier kan je zorgen dat als meerdere systemen op dezelfde manier
met data omgaan, hetzelfde manier waarop data wordt beschreven, zelfde
manier waarop data wordt uitgewisseld of wordt opgeslagen, dat welk
systeem je daar hebt, of je nou Joda hebt of OSF of weet ik veel welke
tool we over twee of drie jaar gebruiken. Als ze wel op dezelfde manier
met die data omgaan, dan maakt dat niet uit. Idem dito als we andere
datastandaarden hebben, maar één systeem dat meerdere van die
datastandaarden ondersteunt, maakt dat ook niet uit. Dat is wel dus
waarom we eerder vandaag al zoveel nadruk legden op die standaarden,
want dat is echt iets waar je aangehaakt moet zijn, dat je weet waar ga
je nou\... Welke standaarden zijn nou degene die we, in de domeinen waar
wij vooral in werken en met de partners waarmee we vooral werken, worden
geadopteerd. Want dat zijn degene waar je op aan wil haken en invloed op
wil uitoefenen. Dus je zou ook moeten kijken naar wat zijn de tools waar
we in de toekomst mee samenwerken. Dan kijk je naar een Aios, dan kijk
je naar een Surf, dan kijk je ook naar wat je onderzoekers doen, welke
tools zij vooral op aangehaakt en wat voor initiatieven zijn er al om op
dat dataniveau daar standaarden voor te ontwikkelen? Dat is, denk ik,
wel superbelangrijk om daarbij bij aangehaakt te blijven. Wat je vaak
ziet, is dat als je een standaard hebt die door een groter deel van een
sector gebruikt wordt, dan blijft die ook gewoon, deels doordat het
legacy is, blijft die ook gewoon wel een langere periode bestaan. Je
krijgt nieuwe versies, maar dat is soepeler dan elke keer van de ene
standaard naar een andere standaard doorswitchen.

## Conclusie

*David:* We lopen tegen het einde van de podcast aan. Ik ga even
proberen in twee zinnen, misschien iets meer, een korte samenvatting te
geven wat er allemaal gezegd is. We begonnen bij waarom research data
management en research software management is opgekomen aan een
universiteit. Dat kwam voornamelijk doordat er eisen waren en wensen ook
vanuit de politiek om goed met data om te gaan. Dat gaat over
data-eigenaarschap, privacy, vanwege die druk, terechte zorgen vanuit
beleidsmakers, overheid, maar ook onderzoekers zelf, zijn er
voorzieningen ingericht bij de universiteit. Maar tegelijkertijd biedt
het ook heel veel kansen voor onderzoekers als die meer kunnen
samenwerken en daardoor onderzoek beter maken. Dat brengt wel nieuwe
vaardigheden met zich mee, ook op het gebied van software. Niet iedereen
kan programmeren, maar misschien moeten daar veel meer soort van
ontzorgende cursussen worden aangeboden aan de universiteit. Ik zie dat
Meron al zijn vinger in de lucht had, misschien wil je iets toevoegen op
dat gebied?

*Meron:* Nee, ik wilde een kleine uitwaaier die net aan het soort van
politiek gerelateerd was, maar dat kreeg ik er niet ingeprikt. Dus ik
zou zeggen: ga verder met je samenvatting. Sorry.

*David:* Het brengt ook eigen problemen met zich mee. Als we alles
willen opslaan, als we alles opslaan, alle versies en alles allemaal
correct doen, brengt dat niet veel te veel data met zich mee? Moeten we
alles opslaan? Brengt dat niet ook andere schade met zich mee? Zowel
misschien internationale veiligheid, kan iedereen gebruik maken van alle
data, maar tegelijkertijd ook veel energie slurpt het op wat schadelijk
kan zijn voor het milieu. Dat zijn grote vragen waar de universiteit mee
moet worstelen de komende tijd. Wat RDS en RDM voornamelijk kan bieden,
is het makkelijker maken voor onderzoekers om hiermee aan de slag te
gaan. Maurice, kan jij het afmaken?

*Maurice:* Zeker. Ik zat ook te denken. Wat ik voornamelijk bij hen
terughoor, is dat het vooral zo gebruikersvriendelijk moet worden
gemaakt van de onderzoeker, zonder dat het hem ontslaat van de
verantwoordelijkheid te nemen voor wat er met de data gebeurt en het
proces van dataverwerking. Dat is volgens mij het belangrijkste
toekomstbeeld wat we willen schetsen. Daar zitten nog randvoorwaarden
aan: standaardisatie van data-interoperabiliteit en dat
wetenschappelijke data en software ook als first-class citizens worden
gezien van het onderzoek. Dat vind ik de belangrijkste take-away van
vandaag. Ik denk dat we hiermee dit kunnen afronden.

## Promo

Maurice: Tot slot, hebben jullie nog wat te promoten? Naar welke
websites moet de luisteraar naartoe? We gaan het rondje even af. Marcel,
heb jij een website waarvan je zegt: daar moeten de luisteraar eens even
naartoe?

*Marcel:* Je moet zeker even naar de research data support portal, een
web waar alle informatie over research data management en research data
support op staat.

*Maurice:* Hartstikke fijn. Meron, heb jij nog een inspirerende plek
waar onderzoekers of luisteraars naartoe moeten?

*Meron:* Ik kan één aanbeveling doen en dat is eerder een event dan een
adres, maar het adres is ook handig. Dat is de maandelijkse software
community Bytes & Bites, waar je pizza krijgt en gelijkgestemden in het
ontwikkelen van code en software voor alle niveaus. Dus als je beginner
bent, is het daar een warm bedje. Als je al zeer ervaren bent, is er ook
genoeg te bespreken. Daar kan je op de VU lib-kalender op inschrijven en
dan krijg je pizza en andere wetenschappers die zich met vergelijkbare
onderwerpen bezighouden.

*Maurice:* Is er een webadres van, Meron?

*Meron:* V het an de lib-co is dat vu-nl.libcal.com.

*Maurice:* Kijk eens aan, dank je wel. Tim.

*Tim:* Het enige waar ik mee in mijn hoofd zit, is de site van ons
innovatieteam, maar die is nog niet live.

*Maurice:* Wel goed dat je het even noemt. We zullen wel in de shownotes
zetten dan als het zover online is. Ik wil jullie heel hartelijk danken,
Tim, Meron, Marcel, voor jullie kennis en expertise en tot de volgende
keer. Dank je wel.
